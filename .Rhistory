select(lon, lat, cbr, id, year, group, PM2.5) %>%
distinct(lon, lat, cbr, id, year, group, PM2.5, .keep_all = TRUE) %>%
filter(complete.cases(.))
multisynth(form = PM2.5 ~ cbr,
unit = id,
time = year,
data = analysis_df,
fixedeff = TRUE,
time_cohort = TRUE,
lambda=.000135,
n_leads = 3,
n_lags = 10)
analysis_df <- merge_df %>%
mutate(year_opened = ifelse(is.na(year_opened),
Inf, year_opened),
cbr = 1 * (year >= year_opened))%>%
select(cbr, id, year, group, PM2.5) %>%
distinct(cbr, id, year, group, PM2.5, .keep_all = TRUE) %>%
filter(complete.cases(.))
multisynth(form = PM2.5 ~ cbr,
unit = id,
time = year,
data = analysis_df,
fixedeff = TRUE,
time_cohort = TRUE,
lambda=.000135,
n_leads = 3,
n_lags = 10)
analysis_df <- merge_df %>%
mutate(year_opened = ifelse(is.na(year_opened),
Inf, year_opened),
cbr = 1 * (year >= year_opened))%>%
select(cbr, id, year, PM2.5) %>%
distinct(cbr, id, year, PM2.5, .keep_all = TRUE) %>%
filter(complete.cases(.))
multisynth(form = PM2.5 ~ cbr,
unit = id,
time = year,
data = analysis_df,
fixedeff = TRUE,
time_cohort = TRUE,
lambda=.000135,
n_leads = 3,
n_lags = 10)
analysis_df <- merge_df %>%
mutate(year_opened = ifelse(is.na(year_opened),
Inf, year_opened),
cbr = 1 * (year >= year_opened))%>%
select(cbr, id, year, PM2.5)
multisynth(form = PM2.5 ~ cbr,
unit = id,
time = year,
data = analysis_df,
fixedeff = TRUE,
time_cohort = TRUE,
lambda=.000135,
n_leads = 3,
n_lags = 10)
analysis_df <- merge_df %>%
mutate(year_opened = ifelse(is.na(year_opened),
Inf, year_opened),
cbr = 1 * (year >= year_opened))
multisynth(form = PM2.5 ~ cbr,
unit = id,
time = year,
data = analysis_df,
fixedeff = TRUE,
time_cohort = TRUE,
lambda=.000135,
n_leads = 3,
n_lags = 10)
analysis_df <- merge_df %>%
mutate(year_opened = ifelse(is.na(year_opened),
Inf, year_opened),
cbr = 1 * (year >= year_opened))%>%
select(cbr, id, year, PM2.5) %>%
distinct(cbr, id, year, PM2.5, .keep_all = TRUE) %>%
filter(complete.cases(.))
multisynth(form = PM2.5 ~ cbr,
unit = id,
time = year,
data = analysis_df,
fixedeff = TRUE,
time_cohort = TRUE,
lambda=.000135,
n_leads = 3,
n_lags = 10)
analysis_df <- merge_df %>%
mutate(year_opened = ifelse(is.na(year_opened),
Inf, year_opened),
cbr = 1 * (year >= year_opened))%>%
select(cbr, id, year, PM2.5) %>%
distinct(cbr, id, year, .keep_all = TRUE) %>%
filter(complete.cases(.))
multisynth(form = PM2.5 ~ cbr,
unit = id,
time = year,
data = analysis_df,
fixedeff = TRUE,
time_cohort = TRUE,
lambda=.000135,
n_leads = 3,
n_lags = 10)
analysis_df <- merge_df %>%
mutate(year_opened = ifelse(is.na(year_opened),
Inf, year_opened),
cbr = 1 * (year >= year_opened))%>%
select(cbr, id, year, PM2.5) %>%
distinct(cbr, id, year, PM2.5, .keep_all = TRUE) %>%
filter(complete.cases(.))
analysis_df <- merge_df %>%
mutate(year_opened = ifelse(is.na(year_opened),
Inf, year_opened),
cbr = 1 * (year >= year_opened))%>%
select(cbr, id, year, PM2.5) %>%
distinct(cbr, id, year, PM2.5, .keep_all = TRUE) %>%
filter(complete.cases(.))
analysis_df <- merge_df %>%
mutate(year_opened = ifelse(is.na(year_opened),
Inf, year_opened),
cbr = 1 * (year >= year_opened),
id = as.factor(id))%>%
select(cbr, id, year, PM2.5) %>%
distinct(cbr, id, year, PM2.5, .keep_all = TRUE) %>%
filter(complete.cases(.))
analysis_df <- merge_df %>%
mutate(year_opened = ifelse(is.na(year_opened),
Inf, year_opened),
cbr = 1 * (year >= year_opened),
id = as.factor(id))%>%
select(cbr, id, year, PM2.5) %>%
distinct(cbr, id, year, PM2.5, .keep_all = TRUE) %>%
filter(complete.cases(.))
multisynth(form = PM2.5 ~ cbr,
unit = id,
time = year,
data = analysis_df,
fixedeff = TRUE,
time_cohort = TRUE,
lambda=.000135,
n_leads = 3,
n_lags = 10)
analysis_df <- merge_df %>%
mutate(year_opened = ifelse(is.na(year_opened),
Inf, year_opened),
cbr = 1 * (year >= year_opened))%>%
select(cbr, id, year, PM2.5) %>%
distinct(cbr, id, year, PM2.5, .keep_all = TRUE) %>%
filter(complete.cases(.))
analysis_df <- distinct(analysis_df, id, year, .keep_all = TRUE)
analysis_df$id <- as.factor(analysis_df$id)
multisynth(form = PM2.5 ~ cbr,
unit = id,
time = year,
data = analysis_df,
fixedeff = TRUE,
time_cohort = TRUE,
lambda=.000135,
n_leads = 3,
n_lags = 10)
ppool_syn <- multisynth(form = PM2.5 ~ cbr,
unit = id,
time = year,
data = analysis_df,
fixedeff = TRUE,
time_cohort = TRUE,
lambda=.000135,
n_leads = 3,
n_lags = 10)
ppool_syn_summ <- summary(ppool_syn)
ppool_syn_summ
print(ppool_syn$nu)
nopool_syn_summ$att
plot(ppool_syn_summ)
plot(ppool_syn_summ, levels = "Average")
plot(ppool_syn_summ)
print(ppool_syn$nu)
ppool_syn_summ <- summary(ppool_syn)
ppool_syn_summ
plot(ppool_syn_summ)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
# Import the Amazon Fulfillment Center Coordinates Rounded table
fc_df <- read.csv("amazon_fulfillment_coordinates_rounded.csv") %>%
rename(lat_rounded_fc = lat_rounded, lng_rounded_fc = lng_rounded)
# Import the RUCC Score 2013 table
rucc_df <- read.csv("us_county_fips_coordinates_rounded.csv") %>% drop_na(RUCC_2013) %>%
rename(county_fips = FIPS)
# Left join the RUCC Score 2013 table and the Amazon coordinates table
fc_rucc <- left_join(rucc_df, fc_df, by = "county_fips")
row_indices <- order(fc_rucc$RUCC_2013)
fc_rucc <- fc_rucc[row_indices, ]
View(fc_rucc)
# Create a list to store the subsets
rucc_score_subsets <- list()
# Loop through each unique RUCC_2013 value
for (i in unique(fc_rucc$RUCC_2013)) {
# Subset the table to only include rows with the current RUCC_2013 value
subset_table <- fc_rucc[fc_rucc$RUCC_2013 == i, ]
# Add the subset table to the list of subsets
rucc_score_subsets[[i]] <- subset_table
}
View(rucc_score_subsets)
View(subset_table)
View(subset_table)
View(rucc_score_subsets)
View(subset_table)
View(subset_table)
View(rucc_score_subsets)
# Loop through each unique RUCC score value
for (i in unique(fc_rucc$RUCC_2013)) {
# Extract the subset table for the current RUCC score value
table_name <- paste0("rucc_score", i )
assign(table_name, as.data.frame(rucc_score_subsets[[i]]))
}
# Create a list of data frames
df_list <- list(rucc_score1, rucc_score2, rucc_score3, rucc_score4, rucc_score5, rucc_score6, rucc_score7, rucc_score8, rucc_score9)
# Loop over each data frame and check the address column for missing values
for (i in 1:9) {
# Check if the specified column is null
if (all(is.na(df_list[[i]]$address))) {
print(paste("There are no Amazon fulfillment centers in  the area where the Rucc socre equals", i, "."))
}
else {
print(paste("There are Amazon fulfillment centers in the area where the Rucc socre equals", i, "."))
# Count the number of non-null rows in "my_column"
non_null_rows <- sum(!is.na(df_list[[i]]$address))
# Print the result
print(paste("The number of Amazon fulfillment centers where the Rucc socre equals", i, "is", non_null_rows))
}
}
View(df_list)
# create a list of the table names
table_names <- c("rucc_score1", "rucc_score2", "rucc_score3", "rucc_score4")
# loop through each table and apply the code
for (name in table_names) {
# get the table object by name
table <- get(name)
# filter the table to include only years 2005-2017 and add a treatment/control column
treatment <- table %>%
filter(year_opened %in% (2005:2017)) %>%
mutate(group = "treatment")
control <- table %>%
filter(is.na(address)) %>%
mutate(group = "control")
# vertically combine the treatment and control groups into a new table
combined_table <- rbind(treatment, control)
# assign the new table to a new object
new_name <- paste0(name, "_combined")
assign(new_name, combined_table)
}
View(combined_table)
View(control)
View(rucc_score4_combined)
View(control)
View(combined_table)
library(augsynth)
library(tidyverse)
merge_df <- read.csv("fc_rucc_pm25_merge.csv")
merge_df <- read.csv("fc_rucc_pm25_merge.csv")
analysis_df <- merge_df %>%
mutate(year_opened = ifelse(is.na(year_opened),
Inf, year_opened),
cbr = 1 * (year >= year_opened))%>%
select(cbr, id, year, PM2.5, RUCC_2013) %>%
distinct(cbr, id, year, PM2.5, RUCC_2013, .keep_all = TRUE) %>%
filter(complete.cases(.))
analysis_df <- distinct(analysis_df, id, year, .keep_all = TRUE)
analysis_df$id <- as.factor(analysis_df$id)
ppool_syn <- multisynth(form = PM2.5 ~ cbr,
unit = id,
time = year,
data = analysis_df,
fixedeff = TRUE,
time_cohort = TRUE,
lambda=.000135,
n_leads = 3,
n_lags = 10)
print(ppool_syn$nu)
ppool_syn_summ <- summary(ppool_syn)
ppool_syn_summ
View(ppool_syn_summ)
View(ppool_syn_summ[["att"]])
plot(ppool_syn_summ)
plot(ppool_syn_summ, levels = "Average")
ppool_syn_rucc <- multisynth(form = PM2.5 ~ cbr| RUCC_2013,
unit = id,
time = year,
data = analysis_df,
fixedeff = TRUE,
time_cohort = TRUE,
lambda=.000135,
n_leads = 3,
n_lags = 5)
print(ppool_syn_rucc$nu)
ppool_syn_rucc_summ <- summary(ppool_syn_rucc)
ppool_syn_rucc_summ
plot(ppool_syn_rucc_summ)
plot(ppool_syn_rucc_summ, levels = "Average")
ppool_syn_rucc_nu <- multisynth(form = PM2.5 ~ cbr| RUCC_2013,
unit = id,
time = year,
data = analysis_df,
fixedeff = TRUE,
time_cohort = TRUE,
nu=.1,
lambda=.000135,
n_leads = 3,
n_lags = 5)
ppool_syn_rucc_nu_summ <- summary(ppool_syn_rucc_nu)
ppool_syn_rucc_nu_summ
plot(ppool_syn_rucc_nu_summ)
plot(ppool_syn_rucc_nu_summ, levels = "Average")
library(augsynth)
library(tidyverse)
library(reshape2)
library(ncdf4)
merge_df <- read.csv("fc_rucc_pm25_merge.csv")
left_join_df <- read.csv("fc_rucc_pm25_left.csv")
left_join_df <- left_join_df %>%
distinct(lon, lat, .keep_all = TRUE)
left_join_df <- left_join_df %>%
group_by(lon, lat) %>%
mutate(id = cur_group_id())
merge_df <- read.csv("fc_rucc_pm25_merge.csv")
merge_df <- merge_df %>%
distinct(lon, lat, .keep_all = TRUE)
merge_df <- merge_df %>%
group_by(lon, lat) %>%
mutate(id = cur_group_id())
write.csv(left_join_df , "fc_rucc_pm25_left.csv", row.names = FALSE)
write.csv(merge_df, "fc_rucc_pm25_merge.csv", row.names = FALSE)
analysis_df <- merge_df %>%
mutate(year_opened = ifelse(is.na(year_opened),
Inf, year_opened),
cbr = 1 * (year >= year_opened))%>%
select(cbr, id, year, PM2.5, RUCC_2013) %>%
distinct(cbr, id, year, PM2.5, RUCC_2013, .keep_all = TRUE) %>%
filter(complete.cases(.))
library(augsynth)
library(tidyverse)
merge_df <- read.csv("fc_rucc_pm25_merge.csv")
analysis_df <- merge_df %>%
mutate(year_opened = ifelse(is.na(year_opened),
Inf, year_opened),
cbr = 1 * (year >= year_opened))%>%
select(cbr, id, year, PM2.5, RUCC_2013) %>%
distinct(cbr, id, year, PM2.5, RUCC_2013, .keep_all = TRUE) %>%
filter(complete.cases(.))
analysis_df <- distinct(analysis_df, id, year, .keep_all = TRUE)
analysis_df$id <- as.factor(analysis_df$id)
ppool_syn <- multisynth(form = PM2.5 ~ cbr,
unit = id,
time = year,
data = analysis_df,
fixedeff = TRUE,
time_cohort = TRUE,
lambda=.000135,
n_leads = 3,
n_lags = 10)
ppool_syn_rucc_nu <- multisynth(form = PM2.5 ~ cbr| RUCC_2013,
unit = id,
time = year,
data = analysis_df,
fixedeff = TRUE,
time_cohort = TRUE,
nu=.1,
lambda=.000135,
n_leads = 3)
library(augsynth)
library(tidyverse)
library(reshape2)
library(ncdf4)
# Set the directory containing the .nc files
setwd("./nc files")
# Get a list of all the .nc files in the directory
nc_files <- list.files(pattern = "*.nc")
# Loop through each .nc file and generate a table from the array
tables <- lapply(nc_files, function(file) {
# Open the .nc file
nc <- nc_open(file)
# Extract the array and add row and column names
array <- ncvar_get(nc, "PM25")
rownames(array) <- ncvar_get(nc, "LON")
colnames(array) <- ncvar_get(nc, "LAT")
# Convert the array into a table with 3 columns
table <- melt(array, varnames = c("lon", "lat"), value.name = paste("PM2.5 in", substr(file, 1, 4)))
# Close the .nc file
nc_close(nc)
# Return the resulting table
return(table)
})
for (i in seq_along(tables)) {
table_name <- paste0("PM25_table", as.character(i + 1999) )
assign(table_name, as.data.frame(tables[[i]]))
}
years <- c(2000:2018)
# create an empty data frame to store the results
PM25_df <- data.frame()
# loop through the years and left join the corresponding table to the existing data frame
for (year in years) {
table_name <- paste0("PM25_table", year)
table <- get(table_name)
if (nrow(PM25_df) == 0) {
PM25_df <- table
} else {
PM25_df <- left_join(PM25_df, table, by = c("lon", "lat"))
}
}
fc_rucc_df = read.csv("./fc_rucc_combined_full.csv") %>%
select(county_fips, State, County_Name, RUCC_2013, lat_rounded, lng_rounded,year_opened, code, group) %>%
rename(lat = lat_rounded,
lon = lng_rounded)
# Left join the 2 tables
left_join_df <- left_join(fc_rucc_df, PM25_df, by = c("lat", "lon")) %>%
pivot_longer(cols=c('PM2.5 in 2000':'PM2.5 in 2018'),
names_to='year',
values_to='PM2.5')
left_join_df$year <- gsub("PM2.5 in ", "", left_join_df$year) %>%
as.numeric(left_join_df$year)
left_join_df <- left_join_df %>%
mutate(group = ifelse(group == "control", 0, 1))
left_join_df <- left_join_df %>%
distinct(lon, lat, year, .keep_all = TRUE)
left_join_df <- left_join_df %>%
group_by(lon, lat) %>%
mutate(id = cur_group_id())
# Merge the 2 tables
merge_df <- merge(fc_rucc_df, PM25_df, by = c("lat", "lon")) %>%
pivot_longer(cols=c('PM2.5 in 2000':'PM2.5 in 2018'),
names_to='year',
values_to='PM2.5')
merge_df$year <- gsub("PM2.5 in ", "", merge_df$year ) %>%
as.numeric(merge_df$year)
merge_df <- merge_df %>%
mutate(group = ifelse(group == "control", 0, 1))
merge_df <- merge_df %>%
distinct(lon, lat, year, .keep_all = TRUE)
merge_df <- merge_df %>%
group_by(lon, lat) %>%
mutate(id = cur_group_id())
write.csv(left_join_df , "fc_rucc_pm25_left.csv", row.names = FALSE)
write.csv(merge_df, "fc_rucc_pm25_merge.csv", row.names = FALSE)
library(augsynth)
library(tidyverse)
merge_df <- read.csv("fc_rucc_pm25_merge.csv")
analysis_df <- merge_df %>%
mutate(year_opened = ifelse(is.na(year_opened),
Inf, year_opened),
cbr = 1 * (year >= year_opened))%>%
select(cbr, id, year, PM2.5, RUCC_2013) %>%
distinct(cbr, id, year, PM2.5, RUCC_2013, .keep_all = TRUE) %>%
filter(complete.cases(.))
analysis_df <- distinct(analysis_df, id, year, .keep_all = TRUE)
analysis_df$id <- as.factor(analysis_df$id)
ppool_syn_rucc_nu <- multisynth(form = PM2.5 ~ cbr| RUCC_2013,
unit = id,
time = year,
data = analysis_df,
fixedeff = TRUE,
time_cohort = TRUE,
nu=.1,
lambda=.000135,
n_leads = 3)
ppool_syn_rucc_nu_summ <- summary(ppool_syn_rucc_nu)
ppool_syn_rucc_nu_summ
plot(ppool_syn_rucc_nu_summ)
plot(ppool_syn_rucc_nu_summ, levels = "Average")
ppool_syn_rucc <- multisynth(form = PM2.5 ~ cbr| RUCC_2013,
unit = id,
time = year,
data = analysis_df,
fixedeff = TRUE,
time_cohort = TRUE,
n_leads = 3)
print(ppool_syn_rucc$nu)
ppool_syn_rucc_summ <- summary(ppool_syn_rucc)
ppool_syn_rucc_summ
ppool_syn <- multisynth(form = PM2.5 ~ cbr,
unit = id,
time = year,
data = analysis_df,
fixedeff = TRUE,
time_cohort = TRUE,
n_leads = 3)
print(ppool_syn$nu)
ppool_syn_summ <- summary(ppool_syn)
ppool_syn_summ
plot(ppool_syn_summ)
plot(ppool_syn_summ, levels = "Average")
plot(ppool_syn_rucc_summ)
plot(ppool_syn_rucc_summ, levels = "Average")
library(ggplot2)
library(tidyverse)
library(base)
# create a data frame with the number of Amazon fulfillment centers in each RUCC score
df <- data.frame(RUCC_score = c(1, 2, 3, 4),
centers_count = c(279, 101, 8, 3))
# create the bar plot
ggplot(df, aes(x = RUCC_score, y = centers_count)) +
geom_bar(stat = "identity") +
labs(x = "RUCC score", y = "Number of fulfillment centers",
title = "Distribution of Amazon fulfillment centers by RUCC score")
# create a data frame with the number of Amazon fulfillment centers in each RUCC score
df <- data.frame(RUCC_score = c(1, 2, 3, 4),
centers_count = c(279, 101, 8, 3))
# create the bar plot
ggplot(df, aes(x = RUCC_score, y = centers_count)) +
geom_bar(stat = "identity") +
labs(x = "RUCC score", y = "Number of fulfillment centers",
title = "Distribution of Amazon fulfillment centers by RUCC score")
ggsave("Distribution of Amazon fulfillment centers by RUCC score.png", plot = last_plot(), width = 10, height = 6)
